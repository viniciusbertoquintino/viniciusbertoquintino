{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "vOISp5PYq4qi",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "os.environ['OPENAI_API_KEY'] = config['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = ChatOpenAI(model_name='gpt-4o', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os documentos\n",
    "loader = TextLoader('base_conhecimento_britadeira.txt')\n",
    "documents = loader.load()\n",
    "# Carregar histórico de conversas \n",
    "historico_conversas = \"\"\"Cliente: Minha britadeira não liga. Chatbot: Você já verificou \n",
    "                         se a bateria está carregada e conectada corretamente?\"\"\"\n",
    "# Pergunta do cliente\n",
    "pergunta = \"Minha britadeira não liga. Eu já veriquei e a bateria está carregada e conectada corretamente\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"context\": \"\\n\".join(doc.page_content for doc in documents),\n",
    "    \"question\": pergunta,\n",
    "    \"historico\": historico_conversas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_base_conhecimento = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"Use o seguinte contexto para responder à pergunta. \n",
    "    Responda apenas com base nas informações fornecidas.\n",
    "    Não forneceça instruções de procedimento já realizados.\n",
    "    Não utilize informações externas ao contexto:\n",
    "    Contexto: {context}\n",
    "    Pergunta: {question}\"\"\"\n",
    ")\n",
    "prompt_historico_conversas = PromptTemplate(\n",
    "    input_variables=[\"historico\", \"question\"],\n",
    "    template=\"\"\"Use o histórico de conversas para responder à pergunta. \n",
    "    Responda apenas com base nas informações fornecidas. \n",
    "    Não forneceça instruções de procedimento já realizados.\n",
    "    Não utilize informações externas ao contexto:\n",
    "    Histórico: {historico}\n",
    "    Pergunta: {question}\"\"\"\n",
    ")\n",
    "prompt_final = PromptTemplate(\n",
    "    input_variables=[\"resposta_base_conhecimento\", \"resposta_historico_conversas\"],\n",
    "    template=\"\"\"Combine as seguintes respostas para gerar uma resposta final,\n",
    "    mas não forneça instruções de procedimentos já realizados:\n",
    "    Resposta da base de conhecimento: {resposta_base_conhecimento}\n",
    "    Resposta do histórico de conversas: {resposta_historico_conversas}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_base_conhecimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as cadeias  \n",
    "chain_base_conhecimento = prompt_base_conhecimento | openai\n",
    "chain_historico_conversas = prompt_historico_conversas | openai\n",
    "chain_final = prompt_final | openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain_base_conhecimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain_historico_conversas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passando dados e executando\n",
    "resultado_base_conhecimento = chain_base_conhecimento.invoke({\"context\": inputs[\"context\"], \"question\": inputs[\"question\"]})\n",
    "resultado_historico_conversas = chain_historico_conversas.invoke({\"historico\": inputs[\"historico\"], \"question\": inputs[\"question\"]})\n",
    "resultado_final = chain_final.invoke({\"resposta_base_conhecimento\": resultado_base_conhecimento, \n",
    "                                      \"resposta_historico_conversas\": resultado_historico_conversas})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resultado Base de Conhecimento:\\n\", resultado_base_conhecimento)\n",
    "print(\"----\")\n",
    "print(\"Resultado Histórico de Conversas:\\n\", resultado_historico_conversas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultado_final.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultado_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
