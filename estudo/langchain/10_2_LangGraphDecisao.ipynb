{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a676714b-5d25-4cb2-9270-557106cd4bd1",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fdabae5-4778-4ce9-acc8-64a783ae4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from duckduckgo_search import DDGS\n",
    "from typing import TypedDict\n",
    "import graphviz\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dbcfd60-b5d7-46d8-b86d-31c6672eba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"OPENAI_API_KEY\"]\n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1\", temperature=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de2494-6627-4338-9f66-32bd5b927d17",
   "metadata": {},
   "source": [
    "# Estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c522887c-17c0-4a90-a384-e058612f93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    pergunta: str  \n",
    "    conteudo: str \n",
    "    resposta: str "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0d675b-7425-4090-abc3-971b0d87697e",
   "metadata": {},
   "source": [
    "# Funções de CallBack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d6254ca-aa10-4de3-a141-a9bc22cd6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recebe_pergunta(state: State) -> State:\n",
    "    print(f\"Usuário perguntou: {state['pergunta']}\")\n",
    "    return {\"pergunta\": state[\"pergunta\"]}\n",
    "\n",
    "def precisa_pesquisar(state: State) -> State:\n",
    "    pergunta = state[\"pergunta\"].lower()\n",
    "    precisa = any(p in pergunta for p in [\"dados\", \"estatísticas\", \"números\", \"pesquisa\"])\n",
    "    print(\"Precisa pesquisar?\", precisa)\n",
    "    # Retorna um dicionário, com chave especial para decisão\n",
    "    return {\"next_step\": \"pesquisar\" if precisa else \"consultar_llm\"}\n",
    "\n",
    "def pesquisar(state: State) -> State:\n",
    "    pergunta = state[\"pergunta\"]\n",
    "    print(f\"Pesquisando no DuckDuckGo: {pergunta}\")\n",
    "\n",
    "    with DDGS() as ddgs:\n",
    "        resultados = ddgs.text(pergunta, max_results=1)\n",
    "\n",
    "    if resultados:\n",
    "        contexto = \"\\n\".join([r[\"body\"] for r in resultados if \"body\" in r])\n",
    "    else:\n",
    "        contexto = \"Nenhum resultado encontrado.\"\n",
    "\n",
    "    return {\"conteudo\": contexto}    \n",
    "\n",
    "def consultar_llm(state: State) -> State:\n",
    "    prompt = ChatPromptTemplate.from_template(\"Responda à seguinte pergunta: {pergunta}\")\n",
    "    chain = prompt | llm\n",
    "    resposta = chain.invoke({\"pergunta\": state[\"pergunta\"]})\n",
    "    print(\"Resposta direta do LLM.\")\n",
    "    return {\"resposta\": resposta.content}\n",
    "\n",
    "def sintetizar(state: State) -> State:\n",
    "    contexto = state.get(\"conteudo\", \"\")\n",
    "    pergunta = state[\"pergunta\"]\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Use o seguinte contexto para responder a pergunta:\n",
    "    Contexto: {contexto}\n",
    "    Pergunta: {pergunta}\n",
    "    Resposta:\"\"\")\n",
    "    chain = prompt | llm\n",
    "    resposta = chain.invoke({\"contexto\": contexto, \"pergunta\": pergunta})\n",
    "    print(\"Resposta sintetizada com contexto.\")\n",
    "    return {\"resposta\": resposta.content}\n",
    "\n",
    "def responder(state: State) -> State:\n",
    "    print(\"\\n Resposta Final:\")\n",
    "    print(state[\"resposta\"])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83acffa2-82bd-4ee8-a611-f41b7e396b3b",
   "metadata": {},
   "source": [
    "# Cria Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953fd2c6-f021-43d3-a9ad-478d1459e7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x15b00531c50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"recebe_pergunta\", RunnableLambda(recebe_pergunta))\n",
    "graph.add_node(\"decisao\", RunnableLambda(precisa_pesquisar))\n",
    "graph.add_node(\"pesquisar\", RunnableLambda(pesquisar))\n",
    "graph.add_node(\"consultar_llm\", RunnableLambda(consultar_llm))\n",
    "graph.add_node(\"sintetizar\", RunnableLambda(sintetizar))\n",
    "graph.add_node(\"responder\", RunnableLambda(responder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d04aa3-1382-49d4-b934-e6a6b5702bd0",
   "metadata": {},
   "source": [
    "# Transições de Estado e Condições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ae3be22-7b5a-4c10-be7d-82c4196f8e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x15b00531c50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.set_entry_point(\"recebe_pergunta\")\n",
    "\n",
    "graph.add_edge(\"recebe_pergunta\", \"decisao\")\n",
    "graph.add_conditional_edges(\n",
    "    \"decisao\",\n",
    "    lambda state: state[\"next_step\"],  \n",
    "    {\n",
    "        \"pesquisar\": \"pesquisar\",\n",
    "        \"consultar_llm\": \"consultar_llm\"\n",
    "    }\n",
    ")\n",
    "graph.add_edge(\"pesquisar\", \"sintetizar\")\n",
    "graph.add_edge(\"consultar_llm\", \"responder\")\n",
    "graph.add_edge(\"sintetizar\", \"responder\")\n",
    "graph.set_finish_point(\"responder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f0a7b-a648-4805-a1b4-4098e288df93",
   "metadata": {},
   "source": [
    "# Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f287c51-0d2a-47a8-8d69-1d7622aad238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TESTE 1:\n",
      "Usuário perguntou: Qual é a capital da Alemanha?\n",
      "Precisa pesquisar? False\n",
      "Resposta direta do LLM.\n",
      "\n",
      " Resposta Final:\n",
      "A capital da Alemanha é Berlim.\n",
      "\n",
      "  TESTE 2:\n",
      "Usuário perguntou: Me mostre dados sobre economia brasileira em 2025.\n",
      "Precisa pesquisar? True\n",
      "Pesquisando no DuckDuckGo: Me mostre dados sobre economia brasileira em 2025.\n",
      "Resposta sintetizada com contexto.\n",
      "\n",
      " Resposta Final:\n",
      "Segundo o Relatório de Política Monetária divulgado pelo Banco Central em 27 de junho de 2024, a estimativa de crescimento da economia brasileira para 2025 foi reduzida para abaixo de 2%. O Banco Central projeta que, ao invés de crescer 2,1% como anteriormente previsto, o Produto Interno Bruto (PIB) do Brasil deve ter um crescimento máximo de 1,9% em 2025. Essa revisão indica uma perspectiva mais cautelosa para o desempenho econômico do país no próximo ano.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pergunta': 'Me mostre dados sobre economia brasileira em 2025.',\n",
       " 'conteudo': 'O Banco Central reduziu a estimativa de crescimento da economia brasileira em 2025 para abaixo de 2%. O número consta no Relatório de Política Monetária, divulgado nesta quinta-feira (27). A revisão dos dados mostra que o Banco Central avalia que ao invés de crescer 2,1% neste ano, a economia terá um crescimento máximo de 1,9%.',\n",
       " 'resposta': 'Segundo o Relatório de Política Monetária divulgado pelo Banco Central em 27 de junho de 2024, a estimativa de crescimento da economia brasileira para 2025 foi reduzida para abaixo de 2%. O Banco Central projeta que, ao invés de crescer 2,1% como anteriormente previsto, o Produto Interno Bruto (PIB) do Brasil deve ter um crescimento máximo de 1,9% em 2025. Essa revisão indica uma perspectiva mais cautelosa para o desempenho econômico do país no próximo ano.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executable = graph.compile()\n",
    "\n",
    "print(\"\\n TESTE 1:\")\n",
    "executable.invoke({\"pergunta\": \"Qual é a capital da Alemanha?\"})\n",
    "\n",
    "print(\"\\n  TESTE 2:\")\n",
    "executable.invoke({\"pergunta\": \"Me mostre dados sobre economia brasileira em 2025.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618ebf2-ec45-4ade-8752-a2a38012e567",
   "metadata": {},
   "source": [
    "# Gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b52a0995-5953-41f6-80b4-08ddc10edd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\trecebe_pergunta(recebe_pergunta)\n",
      "\tdecisao(decisao)\n",
      "\tpesquisar(pesquisar)\n",
      "\tconsultar_llm(consultar_llm)\n",
      "\tsintetizar(sintetizar)\n",
      "\tresponder(responder)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> recebe_pergunta;\n",
      "\tconsultar_llm --> responder;\n",
      "\tdecisao -.-> consultar_llm;\n",
      "\tdecisao -.-> pesquisar;\n",
      "\tpesquisar --> sintetizar;\n",
      "\trecebe_pergunta --> decisao;\n",
      "\tsintetizar --> responder;\n",
      "\tresponder --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dot = executable.get_graph().draw_mermaid()\n",
    "\n",
    "print(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b0a570-395d-4b68-87b7-cdd69c142009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
